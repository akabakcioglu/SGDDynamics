{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg,Statistics,Random,Printf,GZip,Knet,Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Range=3.0; # range of the x values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise_std=0.15; # max noise/value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obligatory arguments listed before \";\" while optional arguments come after \";\".\n",
    "function gen_noisy_gaussian(;range=1.0,noise=0.1)\n",
    "#    x = sort(randn(len)*range) # randn(): normal distributed \n",
    "    x = collect(-Range:0.2:Range)\n",
    "    \n",
    "#    y = exp.(-x.^2).*(-noise*2*(rand(length(x)).-0.5).+1) # fractional noise\n",
    "     y = exp.(-x.^2) + randn(length(x))*noise; # additive gaussian noise\n",
    "    return (x,y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train) = gen_noisy_gaussian(range=Range,noise=Noise_std);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=length(x_train); # number of training data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(x_train,[y_train,exp.(-x_train.^2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose for easier manipulation during training\n",
    "x_train = permutedims(x_train)\n",
    "y_train = permutedims(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layersize = 50; # number of neurons in a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = 1\n",
    "# input = 1\n",
    "# hidden = 50\n",
    "# batchsize = 1\n",
    "# one layer: tahn.(w[hidden,input] * x[input,batchsize] .+ b[hidden,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "w = [0.1*rand(Layersize,1),0.1*rand(Layersize,1),0.1*rand(1,Layersize),0.1*rand(1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions:\n",
    "# w[1]: (hidden x input) - input->hidden weights\n",
    "# x: (input x batchsize) - input\n",
    "# w[2]: (hidden x 1) - input->hidden bias\n",
    "# w[3]: (hidden x output) - hidden-> output weights\n",
    "# w[4]: (output x 1) - hidden->output bias\n",
    "\n",
    "function loss(w,x,y)\n",
    "    guesses = sum(w[3] * tanh.(w[1]*x.+w[2]) .+ w[4],dims=1) # w[1]=w, w[2]=w0, w[3]=w', w[4]=w0'\n",
    "    return mean(abs2,y-guesses)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct the gradient-calculating function\n",
    "lossgradient = grad(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = lossgradient(w,[x_train[1]],[y_train[1]])  # dw has dimnensions of w\n",
    "                                                # output is the gradient w.r.t. the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mytrain!(w;lr=0.1)\n",
    "    for n=1:L\n",
    "        dw = lossgradient(w,[x_train[n]],[y_train[n]]);\n",
    "        for i = 1:length(w)\n",
    "            for j = 1:length(w[i])\n",
    "                w[i][j] -= lr*dw[i][j];\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collect weights after each epoch in an array (trajectory)\n",
    "weights = [ deepcopy(mytrain!(w,lr=0.01)) for epoch=1:1000 ];  # copy only copies the top layer, does not descend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(w,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xplot=collect(-Range:0.01:Range);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = permutedims(sum(w[3] * tanh.(w[1]*permutedims(xplot).+w[2]) .+ w[4],dims=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the converged function and the initial gaussian\n",
    "plot(xplot,[y_pred,exp.(-xplot.^2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the training dataset\n",
    "scatter!(x_train,y_train,leg=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
